# ğŸ¦ **Lauki Finance: Credit Risk Modelling (Classification Model)**

*A portfolio project built as part of the CodeBasics Gen AI & Data Science Bootcamp*

---

## ğŸš€ **Project Overview**

This project is a complete **end-to-end Credit Risk Modelling solution** that predicts the **default probability** of loan applicants and generates a **credit score (300â€“900)** along with actionable risk ratings (Excellent â†’ Poor).

The project simulates a real engagement with **Lauki Finance**, an NBFC that provides loans to customers underserved by traditional banks. Their rapid growth demands a modern, AI-powered system to evaluate borrower risk efficiently and consistently.

The final solution includes:

âœ” A full data cleaning & preprocessing pipeline
âœ” Exploratory data analysis & business-rule validation
âœ” Advanced feature engineering
âœ” Model training with imbalance handling (RUS + SMOTETomek)
âœ” Hyperparameter tuning using Optuna
âœ” Model packaging & versioning
âœ” Deployment-ready Streamlit UI
âœ” Automated PDF credit report generator

---

## ğŸ“Œ **Live App:**

ğŸ”— **[https://ml-project-credit-risk-modelling-codebasics.streamlit.app/](https://ml-project-credit-risk-modelling-codebasics.streamlit.app/)**

## ğŸ“Œ **GitHub Repository:**

ğŸ”— [https://github.com/ruchitha-meenakshi/ml-project-credit-risk-modelling](https://github.com/ruchitha-meenakshi/ml-project-credit-risk-modelling)

---

# ğŸ§© **Business Story: Lauki Financeâ€™s Transformation**

After the success of the S.H.I.E.L.D. Insurance project, Bruce Harley and his AI startup **AtliQ.ai** quickly gained industry attention.
One of the first calls came from **Steve Singh**, the Head of **Lauki Finance**, an NBFC serving borrowers who are unable to obtain loans from traditional banks.

### **The problem?**

Lauki Finance relied heavily on:

* Manual credit evaluation
* Inconsistent decisions
* Slow processing times
* High operational overhead

These bottlenecks restricted business growth and limited their ability to scale.

Seeing potential in Steveâ€™s vision, Bruce reached out to Tony at AtliQ.ai to build a system that could:

âš¡ Automate credit decisioning
âš¡ Reduce dependency on manual reviews
âš¡ Improve risk prediction accuracy
âš¡ Support faster loan approvals
âš¡ Maintain transparency & explainability for regulatory needs

Tony assigned **Peter** as the project lead. What began as a â€œsmall assignmentâ€ turned into a foundational AI initiative for Lauki Finance.

---

# ğŸ¯ **Project Objectives**

### ğŸ¯ Primary Goal

Build a machine learning model that predicts **loan default probability** and generates an **interpretable credit score**.

### ğŸ“Œ Success Criteria (Defined by Lauki Finance)

| Metric                        | Target                                       |
| ----------------------------- | -------------------------------------------- |
| **Recall (Default Class)**    | > 90%                                        |
| **Precision (Default Class)** | > 50%                                        |
| **Explainability**            | Must support rule-based interpretation       |
| **Rank Ordering**             | Must exhibit monotonic decile-level ordering |
| **Real-time Deployment**      | Streamlit web app for decision automation    |

---

# ğŸ§± **Project Structure**

```
ml-project-credit-risk-modelling
â”‚
â”œâ”€â”€ app/                              # Streamlit web application
â”‚   â”œâ”€â”€ main.py                       # UI + feature collection
â”‚   â”œâ”€â”€ prediction_helper.py          # Feature engineering + model scoring
â”‚   â””â”€â”€ report_generator.py           # PDF credit report generator
â”‚
â”œâ”€â”€ artifacts/                        # Final model, scaler & metadata
â”‚   â””â”€â”€ model_data.joblib
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # NOT uploaded (proprietary)
â”‚   â””â”€â”€ processed/                    # Cleaned datasets NOT uploaded (proprietary)
â”‚
â”œâ”€â”€ outputs/                          # EDA, model evaluation artifacts
â”‚   â”œâ”€â”€ figures/                      # ROC, KS, Rank Ordering plots
â”‚   â””â”€â”€ models/                       # EDA/testing pickles
â”‚   â””â”€â”€ tables/                       # Rank Ordering tables
â”œâ”€â”€ scripts/                          # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_cleaning_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ 04_model_evaluation.ipynb
â”‚   â””â”€â”€ imports.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

# ğŸ§  **Technical Stack**

### ğŸ’» Languages & Libraries

* Python 3.10
* Pandas, NumPy
* Scikit-Learn
* XGBoost
* Imbalanced-learn (SMOTE-Tomek)
* Optuna (Hyperparameter tuning)
* Matplotlib, Seaborn
* Joblib
* Streamlit
* FPDF (PDF report generation)

---

# ğŸ” **Model Overview**

This is a **binary classification** problem where:

| Target Variable State | Numeric Value | Business Meaning |           Risk Category            | 
| --------------------- | ------------- | ---------------- | ---------------------------------- |
| Default = False       |        0      | Non-Defaulter    | "Good" Customer (Desired outcome)  |
| Default = True        |        1      | Defaulter        | "Bad" Customer (Event of Interest) |


### ğŸ“Œ Models Explored:

| Model               | Notes                                   |
| ------------------- | --------------------------------------- |
| Logistic Regression | Interpretable, regulation-friendly      |
| Random Forest       | High performance, less explainable      |
| XGBoost             | Strong predictive power, black-box risk |

---

# ğŸ§¹ **Data Cleaning & Business Rule Validation**

Before modeling, several **business rules** were implemented:

### âœ” Processing Fee Validation

* Must NOT exceed **3%** of loan amount
* 5 records violated the rule â†’ removed

### âœ” GST Validation

* Must NOT exceed **20%** of loan amount

### âœ” Net Disbursement

* Must be â‰¤ loan amount

### âœ” Imputation

* Missing categorical: mode
* Missing numeric: domain-informed logic

This ensured a **clean, regulation-ready dataset**.

---

# ğŸ—ï¸ **Feature Engineering**

### Engineered Key Features

| Feature                             | Why Itâ€™s Important                          |
| ----------------------------------- | ------------------------------------------- |
| `loan_to_income`                    | Strongest predictor of repayment capability |
| `delinquency_ratio`                 | Indicates past payment behavior             |
| `avg_dpd_per_delinquency`           | Stability of repayments                     |
| One-hot encoded residence/loan type | Behavioral segmentation                     |
| MinMax scaling                      | Ensures model stability                     |

All transformations were saved with the model to ensure deployability.

---

# âš–ï¸ **Handling Class Imbalance**

Default class was **highly imbalanced**.
Techniques attempted:

### 1ï¸âƒ£ Random Undersampling

* Pros: Balanced data
* Cons: Loss of information

### 2ï¸âƒ£ SMOTE + Tomek Links (Final Choice)

* Pros: Synthetic minority samples + noise removal
* Stable decision boundary
* Best recall score

---

# ğŸ”§ **Hyperparameter Optimization (Optuna)**

A search space was designed for:

* C
* Solver
* Tolerance
* Class weights

Final params:

```
C = 4.46
solver = 'saga'
tol = 6.3e-06
class_weight = 'balanced'
```

---

# ğŸ“ˆ **Model Evaluation**

### âœ” Classification Report (Final Model)

| Metric        | Default Class Result            |
| ------------- | ------------------------------- |
| **Recall**    | **94%** âœ” Meets business target |
| **Precision** | **56%** âœ” Meets business target |
| **F1 Score**  | 70%                             |

---

### âœ” ROC-AUC = **0.98**

Outstanding discrimination capability.

### âœ” Gini Coefficient = **0.96**

Strong rank ordering.

### âœ” KS Statistic = **85.9%**

Excellent separation between â€œGoodâ€ and â€œBadâ€ customers.

### âœ” Decile Ordering

Monotonic ordering achieved â†’ highly deployment-ready.

---

# ğŸŒ **Streamlit App**

The deployed Streamlit application enables:

âœ” Real-time data entry
âœ” Automated feature engineering
âœ” Probability of default calculation
âœ” Credit score generation (300â€“900)
âœ” Risk category: Excellent / Good / Average / Poor
âœ” Downloadable PDF credit report
âœ” Clean, modern UI with custom CSS

ğŸ“Œ **Live App:** [https://ml-project-credit-risk-modelling-codebasics.streamlit.app/](https://ml-project-credit-risk-modelling-codebasics.streamlit.app/)

## ğŸ§¾ **Automated PDF Report Generation**

After generating a prediction, the app allows users to **download a complete credit decision report** as a PDF.

**The report includes:**

* Default Probability
* Calculated Credit Score
* Final Rating
* Full list of model input parameters

This feature simulates a **real NBFC workflow**, enabling easy auditing and documentation of credit decisions.

ğŸ“Œ **Sample PDF Output:**
![PDF Report Demo](<img width="772" height="647" alt="Screenshot 2025-11-28 at 11 03 15" src="https://github.com/user-attachments/assets/4e8624f1-5685-43c4-bd73-9c3995ffa895" />)

---

# ğŸ¨ **App Preview**

### ğŸ¥ Demo Video

https://github.com/user-attachments/assets/4adfe1b8-4013-4069-88e9-e27b2c472db0

---

# ğŸ”’ **Data Privacy Notice**

The dataset used for this project is provided exclusively as part of the CodeBasics Bootcamp and is **NOT publicly distributable**.

To comply with licensing:

* `data/raw/` and `data/processed/` are added to `.gitignore`
* Only `.gitkeep` placeholder files are included
* No proprietary data is uploaded

---

# ğŸ›  **How to Run Locally**

### Step 1 â€” Clone the repository

```bash
git clone https://github.com/ruchitha-meenakshi/ml-project-credit-risk-modelling.git
cd ml-project-credit-risk-modelling
```

### Step 2 â€” Install dependencies

```bash
pip install -r requirements.txt
```

### Step 3 â€” Launch the application

```bash
streamlit run app/main.py
```

---

# ğŸŒ± **Learnings from the Project**

This project helped me strengthen:

âœ” Business-first problem framing
âœ” Data cleaning using domain rules, not just statistics
âœ” Feature engineering for credit datasets
âœ” Model training on imbalanced classification problems
âœ” Hyperparameter tuning with Optuna
âœ” Understanding of regulatory requirements for ML models
âœ” Building a production-grade Streamlit app
âœ” PDF generation & real-time scoring workflow
âœ” Managing model artifacts & reproducibility

---

# ğŸ™Œ **Acknowledgements**

Special thanks to:

* **CodeBasics Team** â€“ for industry-grade project design
* **Dhaval Patel & Hemanand Vadivel** â€“ for guidance
* **AtliQ.ai fictional team** â€“ for driving the narrative

---

# ğŸ‘©â€ğŸ’» **Author**

**Ruchitha Uppuluri**
Aspiring Data Scientist | CodeBasics ML Bootcamp

ğŸ”— LinkedIn: [https://www.linkedin.com/in/ruchithauppuluri](https://www.linkedin.com/in/ruchithauppuluri)

---
